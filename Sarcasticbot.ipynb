{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import pandas as pd\n",
    "\n",
    "# link to the model in case you need it for testing: \n",
    "# model is under hcii-assignment4 subfolder\n",
    "# https://drive.google.com/drive/folders/1ZDG6EIVRn5nDgzOMWIdPdUB5hJGOgGX0?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language models\n",
    "dfdsf\n",
    "\n",
    "Maybe here: https://raw.githubusercontent.com/mkearney/trumptweets/master/data/trumptweets-1515775693.tweets.csv\n",
    "\n",
    "A language model is an algorithm that takes a sequence of words, and outputs the likely next word in the sequence. Most language models output a list of words, each with its probability of occurance. For example, if we had a sentence that started `I would like to eat a hot`, then ideally the algorithm would predict that  the word `dog` had a much higher chance of being the next word than the word `meeting`. \n",
    "\n",
    "Language models are a very powerful building block in natural language processing. They are used for classifying text (e.g. is this review positive or negative?), for answering questions based on text (e.g. \"what is the capital of Finland?\" based on the Wikipedia page on Finland), and language translation (e.g. English to Japanese).\n",
    "\n",
    "## The intuition behind why language models are so broadly useful\n",
    "How can this simple sounding algorithm be that broadly useful? Intuitively, this is because predicting the next word in a sentence requires a lot of information, not just about grammar and syntax, but also about semantics: what things mean in the real-world. For instance, we know that `I would like to eat a hot dog` is semantically reasonable, but `I would like to eat a hot cat` is nonsensical. \n",
    "\n",
    "I trained a simple language model, and asked it to predict the word following `I would like to eat a `. \n",
    "\n",
    "We get:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load all the data \n",
    "In this example, we are going to use a dataset of tweets from [the Onion](https://www.theonion.com), as well as some non-sarcastic news sources. I found this data set on [Kaggle](https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection). \n",
    "\n",
    "Before I started creating this notebook, I downloaded the JSON file to a folder `haii-assignment4'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_path = Path('./haii-assignment4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is in a JSON file, so I am using the `read_json` method. If your data is CSV, use the `read_csv` method instead. \n",
    "\n",
    "We use the `lines=True` argument here because the author formatted each line as a separate JSON object. I think at least half of your time as a data scientist/AI researcher is spent dealing with other people's data formats!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(data_path/'Sarcasm_Headlines_Dataset_v2.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/my-white-...</td>\n",
       "      <td>my white inheritance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/5-ways-to...</td>\n",
       "      <td>5 ways to file your taxes with less stress</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.theonion.com/richard-bransons-glob...</td>\n",
       "      <td>richard branson's global-warming donation near...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://politics.theonion.com/shadow-governmen...</td>\n",
       "      <td>shadow government getting too large to meet in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.huffingtonpost.comhttp://pubx.co/6...</td>\n",
       "      <td>lots of parents know this scenario</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/this-lesb...</td>\n",
       "      <td>this lesbian is considered a father in indiana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/amanda-pe...</td>\n",
       "      <td>amanda peet told her daughter sex is 'a specia...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/what-to-k...</td>\n",
       "      <td>what to know regarding current treatments for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/chris-chr...</td>\n",
       "      <td>chris christie suggests hillary clinton was to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://www.theonion.com/ford-develops-new-suv...</td>\n",
       "      <td>ford develops new suv that runs purely on gaso...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/uber-ceo-...</td>\n",
       "      <td>uber ceo travis kalanick stepping down from tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://www.theonion.com/area-boy-enters-jumpi...</td>\n",
       "      <td>area boy enters jumping-and-touching-tops-of-d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://local.theonion.com/area-man-does-most-...</td>\n",
       "      <td>area man does most of his traveling by gurney</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/leave-no-...</td>\n",
       "      <td>leave no person with disabilities behind</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/lin-manue...</td>\n",
       "      <td>lin-manuel miranda would like to remind you to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/journalis...</td>\n",
       "      <td>60 journalists killed in 2014 as targeting of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>https://www.theonion.com/guard-in-video-game-u...</td>\n",
       "      <td>guard in video game under strict orders to rep...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/healthy-l...</td>\n",
       "      <td>how to live to be 110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>https://www.huffingtonpost.comhttps://www.thed...</td>\n",
       "      <td>cat so scared in shelter won't even look at you</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/bill-clin...</td>\n",
       "      <td>bill clinton shoots down republicans: 'i stron...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://www.theonion.com/secret-service-agent-...</td>\n",
       "      <td>secret service agent not so secret about being...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/this-new-...</td>\n",
       "      <td>this new orange era: the growing divide</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/things-le...</td>\n",
       "      <td>things learned in the first month of having a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/lamelo-ba...</td>\n",
       "      <td>lamelo ball scores 92 points in a single high ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/im-bi-it-...</td>\n",
       "      <td>i'm bi. it took me 21 years to come out of the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28589</th>\n",
       "      <td>https://www.theonion.com/study-83-of-marathon-...</td>\n",
       "      <td>study: 83% of marathon spectators only attend ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28590</th>\n",
       "      <td>https://entertainment.theonion.com/entertainme...</td>\n",
       "      <td>'entertainment weekly' critic lets director re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28591</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/aclu-sues...</td>\n",
       "      <td>aclu sues trump administration over voter frau...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28592</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/uninsured...</td>\n",
       "      <td>the uninsured rate for hispanic kids has hit a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28593</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jeb-bush-...</td>\n",
       "      <td>jeb bush may be the most awkward 2016 candidate</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28594</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/hbo-host-...</td>\n",
       "      <td>dr. oz, mel gibson, &amp; congress called out usin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28595</th>\n",
       "      <td>https://www.theonion.com/man-adds-a-few-person...</td>\n",
       "      <td>man adds a few personalized tracks to standard...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28596</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/when-our-...</td>\n",
       "      <td>when our tears become medicine</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28597</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/michael-d...</td>\n",
       "      <td>michael douglas denies masturbating in front o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28598</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/madeleine...</td>\n",
       "      <td>madeleine albright congratulates jen welter on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28599</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/wisconsin...</td>\n",
       "      <td>tight wisconsin house primary too close to cal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28600</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/diagnosin...</td>\n",
       "      <td>diagnosing and curing our sick health system</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28601</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/cooking-o...</td>\n",
       "      <td>cooking off the cuff: bluefish in saor – a new...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28602</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/omarosa-t...</td>\n",
       "      <td>omarosa turns on trump: wouldn't vote for him ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28603</th>\n",
       "      <td>https://www.theonion.com/area-eyesore-also-a-d...</td>\n",
       "      <td>area eyesore also a data technician</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28604</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/investiga...</td>\n",
       "      <td>new york attorney general conducting 'inquiry'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28605</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/pokemon-g...</td>\n",
       "      <td>get ready to capture pokémon in the real world...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28606</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/amy-schum...</td>\n",
       "      <td>amy schumer pens letter to tampa trump fans wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28607</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/what-our-...</td>\n",
       "      <td>what our grieving family needs from loved ones...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28608</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/stephen-c...</td>\n",
       "      <td>stephen colbert attempts to list everything tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28609</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jack-phil...</td>\n",
       "      <td>bakery owner vows to stop making wedding cakes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28610</th>\n",
       "      <td>https://sports.theonion.com/congressman-picked...</td>\n",
       "      <td>congressman picked last for committee on youth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28611</th>\n",
       "      <td>https://local.theonion.com/grandmother-doesn-t...</td>\n",
       "      <td>grandmother doesn't care for new priest</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28612</th>\n",
       "      <td>https://entertainment.theonion.com/polish-rapp...</td>\n",
       "      <td>polish rapper under fire for use of the word '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28613</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/san-anton...</td>\n",
       "      <td>how san antonio's dominant defense is fueling ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28614</th>\n",
       "      <td>https://www.theonion.com/jews-to-celebrate-ros...</td>\n",
       "      <td>jews to celebrate rosh hashasha or something</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28615</th>\n",
       "      <td>https://local.theonion.com/internal-affairs-in...</td>\n",
       "      <td>internal affairs investigator disappointed con...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28616</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/andrew-ah...</td>\n",
       "      <td>the most beautiful acceptance speech this week...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28617</th>\n",
       "      <td>https://www.theonion.com/mars-probe-destroyed-...</td>\n",
       "      <td>mars probe destroyed by orbiting spielberg-gat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28618</th>\n",
       "      <td>https://www.theonion.com/dad-clarifies-this-no...</td>\n",
       "      <td>dad clarifies this not a food stop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28619 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            article_link  \\\n",
       "0      https://www.theonion.com/thirtysomething-scien...   \n",
       "1      https://www.huffingtonpost.com/entry/donna-edw...   \n",
       "2      https://www.huffingtonpost.com/entry/eat-your-...   \n",
       "3      https://local.theonion.com/inclement-weather-p...   \n",
       "4      https://www.theonion.com/mother-comes-pretty-c...   \n",
       "5      https://www.huffingtonpost.com/entry/my-white-...   \n",
       "6      https://www.huffingtonpost.com/entry/5-ways-to...   \n",
       "7      https://www.theonion.com/richard-bransons-glob...   \n",
       "8      https://politics.theonion.com/shadow-governmen...   \n",
       "9      https://www.huffingtonpost.comhttp://pubx.co/6...   \n",
       "10     https://www.huffingtonpost.com/entry/this-lesb...   \n",
       "11     https://www.huffingtonpost.com/entry/amanda-pe...   \n",
       "12     https://www.huffingtonpost.com/entry/what-to-k...   \n",
       "13     https://www.huffingtonpost.com/entry/chris-chr...   \n",
       "14     https://www.theonion.com/ford-develops-new-suv...   \n",
       "15     https://www.huffingtonpost.com/entry/uber-ceo-...   \n",
       "16     https://www.theonion.com/area-boy-enters-jumpi...   \n",
       "17     https://local.theonion.com/area-man-does-most-...   \n",
       "18     https://www.huffingtonpost.com/entry/leave-no-...   \n",
       "19     https://www.huffingtonpost.com/entry/lin-manue...   \n",
       "20     https://www.huffingtonpost.com/entry/journalis...   \n",
       "21     https://www.theonion.com/guard-in-video-game-u...   \n",
       "22     https://www.huffingtonpost.com/entry/healthy-l...   \n",
       "23     https://www.huffingtonpost.comhttps://www.thed...   \n",
       "24     https://www.huffingtonpost.com/entry/bill-clin...   \n",
       "25     https://www.theonion.com/secret-service-agent-...   \n",
       "26     https://www.huffingtonpost.com/entry/this-new-...   \n",
       "27     https://www.huffingtonpost.com/entry/things-le...   \n",
       "28     https://www.huffingtonpost.com/entry/lamelo-ba...   \n",
       "29     https://www.huffingtonpost.com/entry/im-bi-it-...   \n",
       "...                                                  ...   \n",
       "28589  https://www.theonion.com/study-83-of-marathon-...   \n",
       "28590  https://entertainment.theonion.com/entertainme...   \n",
       "28591  https://www.huffingtonpost.com/entry/aclu-sues...   \n",
       "28592  https://www.huffingtonpost.com/entry/uninsured...   \n",
       "28593  https://www.huffingtonpost.com/entry/jeb-bush-...   \n",
       "28594  https://www.huffingtonpost.com/entry/hbo-host-...   \n",
       "28595  https://www.theonion.com/man-adds-a-few-person...   \n",
       "28596  https://www.huffingtonpost.com/entry/when-our-...   \n",
       "28597  https://www.huffingtonpost.com/entry/michael-d...   \n",
       "28598  https://www.huffingtonpost.com/entry/madeleine...   \n",
       "28599  https://www.huffingtonpost.com/entry/wisconsin...   \n",
       "28600  https://www.huffingtonpost.com/entry/diagnosin...   \n",
       "28601  https://www.huffingtonpost.com/entry/cooking-o...   \n",
       "28602  https://www.huffingtonpost.com/entry/omarosa-t...   \n",
       "28603  https://www.theonion.com/area-eyesore-also-a-d...   \n",
       "28604  https://www.huffingtonpost.com/entry/investiga...   \n",
       "28605  https://www.huffingtonpost.com/entry/pokemon-g...   \n",
       "28606  https://www.huffingtonpost.com/entry/amy-schum...   \n",
       "28607  https://www.huffingtonpost.com/entry/what-our-...   \n",
       "28608  https://www.huffingtonpost.com/entry/stephen-c...   \n",
       "28609  https://www.huffingtonpost.com/entry/jack-phil...   \n",
       "28610  https://sports.theonion.com/congressman-picked...   \n",
       "28611  https://local.theonion.com/grandmother-doesn-t...   \n",
       "28612  https://entertainment.theonion.com/polish-rapp...   \n",
       "28613  https://www.huffingtonpost.com/entry/san-anton...   \n",
       "28614  https://www.theonion.com/jews-to-celebrate-ros...   \n",
       "28615  https://local.theonion.com/internal-affairs-in...   \n",
       "28616  https://www.huffingtonpost.com/entry/andrew-ah...   \n",
       "28617  https://www.theonion.com/mars-probe-destroyed-...   \n",
       "28618  https://www.theonion.com/dad-clarifies-this-no...   \n",
       "\n",
       "                                                headline  is_sarcastic  \n",
       "0      thirtysomething scientists unveil doomsday clo...             1  \n",
       "1      dem rep. totally nails why congress is falling...             0  \n",
       "2      eat your veggies: 9 deliciously different recipes             0  \n",
       "3      inclement weather prevents liar from getting t...             1  \n",
       "4      mother comes pretty close to using word 'strea...             1  \n",
       "5                                   my white inheritance             0  \n",
       "6             5 ways to file your taxes with less stress             0  \n",
       "7      richard branson's global-warming donation near...             1  \n",
       "8      shadow government getting too large to meet in...             1  \n",
       "9                     lots of parents know this scenario             0  \n",
       "10     this lesbian is considered a father in indiana...             0  \n",
       "11     amanda peet told her daughter sex is 'a specia...             0  \n",
       "12     what to know regarding current treatments for ...             0  \n",
       "13     chris christie suggests hillary clinton was to...             0  \n",
       "14     ford develops new suv that runs purely on gaso...             1  \n",
       "15     uber ceo travis kalanick stepping down from tr...             0  \n",
       "16     area boy enters jumping-and-touching-tops-of-d...             1  \n",
       "17         area man does most of his traveling by gurney             1  \n",
       "18              leave no person with disabilities behind             0  \n",
       "19     lin-manuel miranda would like to remind you to...             0  \n",
       "20     60 journalists killed in 2014 as targeting of ...             0  \n",
       "21     guard in video game under strict orders to rep...             1  \n",
       "22                                 how to live to be 110             0  \n",
       "23       cat so scared in shelter won't even look at you             0  \n",
       "24     bill clinton shoots down republicans: 'i stron...             0  \n",
       "25     secret service agent not so secret about being...             1  \n",
       "26               this new orange era: the growing divide             0  \n",
       "27     things learned in the first month of having a ...             0  \n",
       "28     lamelo ball scores 92 points in a single high ...             0  \n",
       "29     i'm bi. it took me 21 years to come out of the...             0  \n",
       "...                                                  ...           ...  \n",
       "28589  study: 83% of marathon spectators only attend ...             1  \n",
       "28590  'entertainment weekly' critic lets director re...             1  \n",
       "28591  aclu sues trump administration over voter frau...             0  \n",
       "28592  the uninsured rate for hispanic kids has hit a...             0  \n",
       "28593    jeb bush may be the most awkward 2016 candidate             0  \n",
       "28594  dr. oz, mel gibson, & congress called out usin...             0  \n",
       "28595  man adds a few personalized tracks to standard...             1  \n",
       "28596                     when our tears become medicine             0  \n",
       "28597  michael douglas denies masturbating in front o...             0  \n",
       "28598  madeleine albright congratulates jen welter on...             0  \n",
       "28599  tight wisconsin house primary too close to cal...             0  \n",
       "28600       diagnosing and curing our sick health system             0  \n",
       "28601  cooking off the cuff: bluefish in saor – a new...             0  \n",
       "28602  omarosa turns on trump: wouldn't vote for him ...             0  \n",
       "28603                area eyesore also a data technician             1  \n",
       "28604  new york attorney general conducting 'inquiry'...             0  \n",
       "28605  get ready to capture pokémon in the real world...             0  \n",
       "28606  amy schumer pens letter to tampa trump fans wh...             0  \n",
       "28607  what our grieving family needs from loved ones...             0  \n",
       "28608  stephen colbert attempts to list everything tr...             0  \n",
       "28609  bakery owner vows to stop making wedding cakes...             0  \n",
       "28610  congressman picked last for committee on youth...             1  \n",
       "28611            grandmother doesn't care for new priest             1  \n",
       "28612  polish rapper under fire for use of the word '...             1  \n",
       "28613  how san antonio's dominant defense is fueling ...             0  \n",
       "28614       jews to celebrate rosh hashasha or something             1  \n",
       "28615  internal affairs investigator disappointed con...             1  \n",
       "28616  the most beautiful acceptance speech this week...             0  \n",
       "28617  mars probe destroyed by orbiting spielberg-gat...             1  \n",
       "28618                 dad clarifies this not a food stop             1  \n",
       "\n",
       "[28619 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, some of this dataset is drawn from the onion, the rest is drawn from places like the Huffington Post which publish real news, not satire. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1a: Examine the data set (5 points)\n",
    "\n",
    "Before we go off adventuring, let's first see what this dataset looks like. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: How large is this dataset? Is it balanced? (1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14985\n",
       "1    13634\n",
       "Name: is_sarcastic, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert code here to check size of dataset, and how many are positive (is_sarcastic = 1) and how many negative?\n",
    "# Hint: Your output will look like this.\n",
    "\n",
    "df.is_sarcastic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer: \n",
    "There are 14985 negatives and 13634 positives, it is pretty much balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: How long on average is each headline? (4 points)\n",
    "Longer text = more information. We want to see what the length of the headline is in order to see how much information it may have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    28619.000000\n",
       "mean         9.052553\n",
       "std          3.390990\n",
       "min          1.000000\n",
       "25%          7.000000\n",
       "50%          9.000000\n",
       "75%         11.000000\n",
       "max        150.000000\n",
       "Name: headline, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert code here to find the average length of headline (in words)\n",
    "## Hint: see https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.count.html \n",
    "# the '\\s' regex looks for spaces.\n",
    "\n",
    "df.headline.str.count('\\s').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer: \n",
    "Each headline has around 9.05 spaces, which means, on average, each headline has around 10 words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Build a language model that knows how to write news headlines\n",
    "\n",
    "This is the first step of our project that will be using a machine learning model. \n",
    "\n",
    "We are going to use the [fast.ai](https://fast.ai/) library to create this model. If you need help with understanding this section, look at the fast.ai documentation -- it is fantastic! The steps below are modified from the [online tutorial](https://docs.fast.ai/text.html#Quick-Start:-Training-an-IMDb-sentiment-model-with-ULMFiT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai.text import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: if this import fails for you, make sure you've installed fastai first. Do that by creating a new cell, and typing `!pip install fastai`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = (TextList.from_df(df, path=data_path, cols='headline').split_none().label_for_lm().databunch())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So here is what happened above. \n",
    "\n",
    "First, we tell fastai that we want to work on a list of texts (headlines in our case), that are stored in a dataframe (that's the `TextList.from_df` part.) We also pass in our data path, so after we process our data, we can store it at that location. Finally, we tell it where to look for the headline in the dataframe (which column to use, `cols=`). \n",
    "\n",
    "Then there are two other important parts. We'll take it from the end. A `databunch` is a fastai convenience. It keeps all your training, validation and test data together. But what kind of validation data do we need for a language model? Remember that a language model predicts the next word in an input sequence of words. So, we can't just take some of the headlines and set them aside as validation. Instead, we want to use all the sentences and validate whether we can guess the right next word some fraction of the time. So, we first say `split_none` so you use all your data. Then we say `label_for_lm` so it labels the \"next word\" as the label for each sequence of words. It's a clever method -- see the source if you're curious!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save('data_lm_export.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save this databunch. We'll use this saved copy later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2a: Learn the model\n",
    "\n",
    "Now that we have the data, it's time to train the model.\n",
    "\n",
    "Now, we *could* learn a language model from scratch. But we're instead going to cheat. We're going to use a pretrained language model, and finetune it for our purpose. Specifically, we're going to use a model trained on the `Wikitext-103` corpus. \n",
    "\n",
    "One way to understand it is to think of our pre-trained model is as a model that can predict the next word in a Wikipedia article. We want to train it to write headlines instead. Since headlines still have to sound like English, ie. follow grammar, syntax, be generally plausible etc, being able to predict the next word in Wikipedia is super useful. It allows us to start with a model that already knows some English, and then just train it for writing headlines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `AWD_LSTM` is the pretrained Wikipedia model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.053015</td>\n",
       "      <td>#na#</td>\n",
       "      <td>08:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once trained, it's time to write some headlines! We give it a starting sequence `Students protest ` and see what it comes up with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Students protest  action from group after school'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"Students protest \", n_words=5, no_unk=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good, huh? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Fed is expected to win 40 money'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('The Fed is expected to', n_words=3, no_unk=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, it's not perfect! Let's make it a little better. \n",
    "\n",
    "The `unfreeze` below is telling fastai to allow us to change the weights throughout the model. We do this when we want to make the model generate text that's more similar to our headlines (than to Wikipedia). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.199674</td>\n",
       "      <td>#na#</td>\n",
       "      <td>12:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(cyc_len=1, max_lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New Study report says the business has'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('New Study', n_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'16 Problems from week of evening ,'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('16 Problems', n_words=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now let's save our hard work. We'll use this later. (Pssst: why is it called an encoder? Look at the Fastai docs to find out!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('headlines-awd.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we also want to save the whole model, so we can reuse it in our twitter bot. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export('headlines-lm.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2b: See how well the language model works (15 points)\n",
    "\n",
    "Try generating a few more headlines. Then, answer the following questions. Wherever possible, show what code you ran, or what predictions you asked it for. *Suggestion: Try using punctuations, numbers, texts of different lengths etc.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What is the effect of starting with longer strings? (5 points)\n",
    "\n",
    "We could start our headline generation with just one word, e.g. `learn.predict('White', n_words=9)` or with many: `learn.predict('White House Says Whistleblower Did', n_words=5)`. What is the difference you see in the kinds of headlines generated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer:\n",
    "I feel like feeding it with shorter strings give it more variabilities in the rest of the sentence. It could by chance write a good sentence (e.g. 'White house is suffering from too many needed medical measures'), but it could also write something that makes no sense at all (e.g. \"White poll n shows americans ' maturity as one and\"). I think the reason is that the language model predicts every word based on the previous information it has. At the beginning it does not have much information in hand, and could by chance make bad choices for the next word (e.g. \"white behold../ white leg.../ white middle losers...\") but if it did make a good choice of the next word (e.g. \"white house...\") the sentence usually tends to make good sense. \n",
    "\n",
    "Feeding the long strings often has good connection between adjacent words (e.g. it often predicts \"not\" after \"did\"). Since we only let it produce 5 words, there isn't much it can do, and thus produce less variability. The only problem of giving long string is the language model does not know it should finish the sentence in 5 words, and it often does not finish the sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'White house holmes waiting for lady to speak about her'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your answer here. Insert more cells if you want to insert code etc.\n",
    "learn.predict('White', n_words=9)\n",
    "#learn.predict('White House Says Whistleblower Did', n_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'White House says whistleblower did not certain country where it'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('White House says whistleblower did', n_words=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: What aspects of the task of generating headlines does our language model do well? (5 points)\n",
    "For example, does it get grammar right? Does it know genders of people or objects? etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here. Insert more cells if you want to insert code etc.\n",
    "\n",
    "1. The language model is doing pretty good in matching tense. For example, when I only give it \"he is\" as an input, it successfully determines that a verb that comes after \"he is\" should be in present continuous tense. So the model outputs \"he is making the first trip in australia\".\n",
    "\n",
    "2. The language model is doing pretty good in word connections. e.g. The long string 'White House says whistleblower did' has \"did\" as the last word, the language model often gives \"n't\" as the next word to form \"didn't\". \n",
    "\n",
    "3. The model is also capable of detecting quantity. When I feed it \"we\", the verb is always plural -> \"we have to...\", \"we celebrate...\" and when I feed it someone's name, it will use singular verb like \"believes\", \"says\"; when i feed it with a number like \"20\", it outputs a plural noun, when I feed in \"one\", it outputs someting like \"one reporter steps...\"\n",
    "\n",
    "4. the model can also detect gender well. When I tried people like \"Trump said\", the language model will correctly output \"he/his\" as the next word. When I tried \"Taylor Swift\" or \"my grandma\" it will output \"she/her\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### THE FOLLOWING ARE EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20 personal documents that have already been altered and extended'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('20', n_words=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reporter steps forward and makes huge walks off two'"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('one', n_words=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'white house is not obamacare news colleague xxbos lady mason reminds a'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('white house is', n_words=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trump said his final letter to man ( son )'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('Trump said', n_words=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Taylor Swift said she threw her obituary for . J.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('Taylor Swift said', n_words=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: What aspects of the task of generating headlines does our model do poorly? (5 points)\n",
    "What does it frequently get wrong? Why might it make these mistakes?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "\n",
    "1. When we restrict the sentence to predict certain number of words, the classifier has little sense of when it should finish a sentence. I guess because the machanism is to output the next string based on the previous strings, so it only cares if the next string connects well with the previous, without considering what word it shoud use to end the sentence.\n",
    "\n",
    "2. I feel like it does propositions pretty poorly. I think the problem is a word can connect with many different propositions (e.g. \"I sit at\" or \"I sit under\" or \"I sit on\" or \"I sit down\") but when the context is different, some propositions are appropriate but some are not (e.g. 'I travel on airport first time...')\n",
    "\n",
    "3. It outputs random words like 'xxbos' and random punctuations. e.g. \"Taylor Swift ' new ' watched video ' recording studio has\" or  \"Trump . n't n't to accommodate him to n't rebel\" or \"Trump 's actions against trump improve ratings for tourists xxbos\". In the language model, 'xxbos' stands for the start of a new sentence and the random punctuations come from other tokenization rules (e.g. didn't is parsed into did and n't and hers' might be hers and ', so these punctuations were treated as a separated word). I think having 'xxbos' in the sentences indicates the next word is the first word of a new sentence. But it makes no sense to users on twitter when the chatbot writes a sentence like this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Learn a classifier to see which headlines are satire\n",
    "\n",
    "Remember, our dataset has some stories that are satire (from the Onion) and others that are real. Now, we're going to train a classifier to distinguish one from the other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = (TextList.from_df(df=df, path=data_path, vocab= data_lm.train_ds.vocab, cols='headline').split_by_rand_pct(valid_pct=0.2).label_from_df(cols='is_sarcastic').databunch())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using a similar databunch method as we did for our language model above. Here, we are using `split_by_rand_pct` so we keep some fraction of our dataset as a validation set. There is one other trick: `vocab= data_lm.train_ds.vocab` ensures that our classifier only uses words that we have in our language model -- so it never deals with words it hasn't encountered before. (Consider: why is this important?)\n",
    "\n",
    "See if you can work out what the other arguments are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos hot wheels ranked number one toy for rolling down ramp , knocking over xxunk that send xxunk down a funnel , dropping onto teeter - xxunk that yanks on string , causing xxunk system to raise wooden block , xxunk series of twine xxunk that unwind spring , launching tennis ball across room , xxunk tire down slope until it hits power switch , xxunk table fan that blows</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos top 3 reasons why 400 xxunk xxunk is / is not the end of the world , or how i learned to stop worrying and love air xxunk . part 1 : the numbers</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos ' yes , but how did he die ? ' xxunk american public asks of recent celebrity death while xxunk delicate , xxunk hands together and smiling xxunk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos greece 's rock portrait gallery , from xxunk xxunk to de xxunk 's nose : suspended in mid - air on the looney front , part ii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos ' why are you still sleeping on u.s . women 's soccer ? ' asks sports website 's first article about women 's soccer in four years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above: what our data looks like after we apply the vocabulary restriction. `xxunk` is an unknown word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: we're creating a classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = text_classifier_learner(data=data_clas, arch=AWD_LSTM, drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that language model we saved earlier? It's time load it back!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (22896 items)\n",
       "x: TextList\n",
       "xxbos xxunk scientists unveil doomsday clock of hair loss,xxbos dem rep . totally nails why congress is falling short on gender , racial equality,xxbos eat your xxunk : 9 xxunk different recipes,xxbos my white inheritance,xxbos 5 ways to file your taxes with less stress\n",
       "y: CategoryList\n",
       "1,0,0,0,0\n",
       "Path: haii-assignment4;\n",
       "\n",
       "Valid: LabelList (5723 items)\n",
       "x: TextList\n",
       "xxbos hilton head island is the best,xxbos fema unveils nationwide phone tree in case of emergency,xxbos migrant and refugee children find a home in greece 's xxunk schools,xxbos new york city announces subway just for amazon employees now,xxbos little boy gives himself epic pep talk before jumping into a pool\n",
       "y: CategoryList\n",
       "0,1,0,1,0\n",
       "Path: haii-assignment4;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(11152, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(11152, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x1a26ade510>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('haii-assignment4'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: ...\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(11152, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(11152, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.load_encoder('headlines-awd.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here? \n",
    "\n",
    "Here's the trick: a language model predicts the next word in a sequence using all the information it has so far (all the previous words). When we train a classifier, we ask it to predict the label (satire or not) instead of the next word. \n",
    "\n",
    "The intuition here is that if you can tell what the next word in a sentence is, you can tell if it is satirical. (Similarly, if you can can tell what the next word in an email is, you can tell if it is spam, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.452269</td>\n",
       "      <td>0.382194</td>\n",
       "      <td>0.830683</td>\n",
       "      <td>04:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classify.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above: this is similar to `unfreeze()` that we used before. Except, you only allow a few layers of your model to change. Then we can train again, similar to using `unfreeze()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.391429</td>\n",
       "      <td>0.333494</td>\n",
       "      <td>0.856194</td>\n",
       "      <td>05:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classify.fit_one_cycle(1, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! An accuracy of 85%! That sounds great, and for not that much work. \n",
    "\n",
    "Now, let's try it on some headlines, to see how well it does. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: try out the classifier (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.9533, 0.0467]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(\"Despair for Many and Silver Linings for Some in California Wildfires\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here in the output, the first part of this tuple is the chosen category (`0`, i.e. not satire), and the last part is an array of probabilities. The classifier suggests that the headline (which I got from the [New York Times](https://www.nytimes.com/2019/10/29/us/california-fires-homes.html?action=click&module=Top%20Stories&pgtype=Homepage)) is not satire, with about an 86% confidence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4a: Try out this classifier (10 points)\n",
    "\n",
    "Below, try the classifier with some headlines, real or made up (including made up by the language model above). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two headlines that the classifier correctly classifies (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.0827, 0.9173]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a satire that is classified correctly\n",
    "classify.predict(\"horrified nurses discover 40-pound baby after accidentally leaving it in incubator over weekend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.9957, 0.0043]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is generated by the language model above, correctly classified as not satire\n",
    "classify.predict(\"16 Problems of life on the street\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two headlines that the classifier classifies incorrectly (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.7345, 0.2655]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is from the Daily Mash. A man who extended his life span by avoiding processed meat bitterly said it is not worth it\n",
    "classify.predict(\"it wasn't worth it, says 103-year-old vegetarian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.9207, 0.0793]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a satire headline I found on twitter. There are only 300 million+ people in the entire United States\n",
    "classify.predict(\"taylor swift inspires 200 million fans to register to vote in tennessee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to find two headlines that the classifier is really confident about, but classifies incorrectly. We want the confidence of the prediction to be at least 85%.\n",
    "\n",
    "One headline is anything you want to write. Another must be a real headline (not satire) that you could trick the classifier into misclassifying changing only one word. For instance, taking `\"Despair for Many and Silver Linings for Some in California Wildfires\"`, a real NYTimes headline, you can change it to `\"Despair for Many and Silver Linings for Some in Oregon Wildfires\"` (note that this particular change does not cause the classifier to misclassify)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.9649, 0.0351]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Insert one headline that the classifier classifies incorrectly, with false high confidence. (4 points)\n",
    "\n",
    "## 1.\n",
    "# this is pretty funny to me (modified from a real headline) but the classifier confidently said this is not a satire\n",
    "classify.predict(\"running a marathon adds 30 minutes to your life but takes 180 minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.\n",
    "# the original headline is: i love going to the dentist says psychopath with perfect smile\n",
    "# source: https://www.thedailymash.co.uk/news/lifestyle/i-love-the-dentist-says-psychopath-with-perfect-smile-20190927189363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.8990, 0.1010]))"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original headline has 0.8990 confidence it is not a satire\n",
    "test_text= \"i love going to the dentist says psychopath with perfect smile\"\n",
    "classify.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace;\"><span title=\"0.237\" style=\"background-color: rgba(220, 220, 236, 0.5);\">xxbos</span> <span title=\"0.424\" style=\"background-color: rgba(176, 175, 212, 0.5);\">i</span> <span title=\"0.371\" style=\"background-color: rgba(189, 190, 220, 0.5);\">love</span> <span title=\"0.433\" style=\"background-color: rgba(174, 173, 210, 0.5);\">going</span> <span title=\"0.174\" style=\"background-color: rgba(231, 229, 241, 0.5);\">to</span> <span title=\"0.239\" style=\"background-color: rgba(219, 219, 235, 0.5);\">the</span> <span title=\"0.208\" style=\"background-color: rgba(225, 224, 238, 0.5);\">xxunk</span> <span title=\"0.410\" style=\"background-color: rgba(179, 178, 214, 0.5);\">says</span> <span title=\"1.000\" style=\"background-color: rgba(63, 0, 125, 0.5);\">psychopath</span> <span title=\"0.192\" style=\"background-color: rgba(227, 226, 239, 0.5);\">with</span> <span title=\"0.415\" style=\"background-color: rgba(178, 177, 213, 0.5);\">perfect</span> <span title=\"0.372\" style=\"background-color: rgba(188, 189, 220, 0.5);\">smile</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2375, 0.4240, 0.3709, 0.4332, 0.1744, 0.2393, 0.2085, 0.4104, 1.0000,\n",
       "        0.1923, 0.4153, 0.3724])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_ci.show_intrinsic_attention(test_text,cmap=cm.Purples)\n",
    "txt_ci.intrinsic_attention(test_text)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.4342, 0.5658]))"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#changed headline has 0.4342 confidence it is a satire\n",
    "test_text= \"farmers love going to the dentist says psychopath with perfect smile\"\n",
    "classify.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace;\"><span title=\"0.256\" style=\"background-color: rgba(216, 216, 234, 0.5);\">xxbos</span> <span title=\"0.790\" style=\"background-color: rgba(98, 66, 156, 0.5);\">farmers</span> <span title=\"0.403\" style=\"background-color: rgba(181, 180, 215, 0.5);\">love</span> <span title=\"0.465\" style=\"background-color: rgba(166, 164, 205, 0.5);\">going</span> <span title=\"0.156\" style=\"background-color: rgba(233, 232, 242, 0.5);\">to</span> <span title=\"0.197\" style=\"background-color: rgba(227, 226, 239, 0.5);\">the</span> <span title=\"0.167\" style=\"background-color: rgba(232, 230, 241, 0.5);\">xxunk</span> <span title=\"0.394\" style=\"background-color: rgba(183, 184, 217, 0.5);\">says</span> <span title=\"1.000\" style=\"background-color: rgba(63, 0, 125, 0.5);\">psychopath</span> <span title=\"0.158\" style=\"background-color: rgba(233, 232, 242, 0.5);\">with</span> <span title=\"0.360\" style=\"background-color: rgba(191, 192, 221, 0.5);\">perfect</span> <span title=\"0.322\" style=\"background-color: rgba(200, 201, 226, 0.5);\">smile</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2558, 0.7902, 0.4027, 0.4645, 0.1563, 0.1972, 0.1673, 0.3940, 1.0000,\n",
       "        0.1575, 0.3604, 0.3222])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_ci.show_intrinsic_attention(test_text,cmap=cm.Purples)\n",
    "txt_ci.intrinsic_attention(test_text)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4b: What kinds of headlines are misclassified? (10 points)\n",
    "\n",
    "Write your hypothesis below on what kinds of headlines are misclassified. If it helps you, use the [TextClassificationInterpretation](https://docs.fast.ai/text.learner.html#TextClassificationInterpretation) utility. Show your work, especially if you use this utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show work here\n",
    "import matplotlib.cm as cm\n",
    "txt_ci = TextClassificationInterpretation.from_learner(classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1:\n",
    "No word besides 'to' can be recognized by the language model, but this structure still makes the classifier thinks this is a satire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.1715, 0.8285]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = \"zambia exports metals to ethiopia\"\n",
    "classify.predict(test_text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace;\"><span title=\"0.633\" style=\"background-color: rgba(126, 121, 184, 0.5);\">xxbos</span> <span title=\"1.000\" style=\"background-color: rgba(63, 0, 125, 0.5);\">xxunk</span> <span title=\"0.600\" style=\"background-color: rgba(134, 130, 188, 0.5);\">xxunk</span> <span title=\"0.699\" style=\"background-color: rgba(115, 99, 172, 0.5);\">xxunk</span> <span title=\"0.362\" style=\"background-color: rgba(191, 192, 221, 0.5);\">to</span> <span title=\"0.561\" style=\"background-color: rgba(143, 139, 193, 0.5);\">xxunk</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.6329, 1.0000, 0.5998, 0.6989, 0.3625, 0.5610])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_ci.show_intrinsic_attention(test_text,cmap=cm.Purples)\n",
    "txt_ci.intrinsic_attention(test_text)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2:\n",
    "The following series of sentences compare the effects of individual words (farmers vs. I vs. trump; spreading vs. putting). \n",
    "* When the subject is farmer, the classifier thinks the headline is a satire. \n",
    "* When the subject is 'trump', the classifier shifts more attention to 'celebrates' and 'spreading' and become even more certain that it is a satire. \n",
    "* When the subject is 'I', the classifier paid more attention to 'celebrate' but paid less attention to everything else and became 90%+ sure it is not a satire.\n",
    "* When I used \"putting\" instead of \"spreading\", it shifted more attention to the sentence after 'by' and was less confident that it is a satire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace;\"><span title=\"0.331\" style=\"background-color: rgba(198, 199, 225, 0.5);\">xxbos</span> <span title=\"1.000\" style=\"background-color: rgba(63, 0, 125, 0.5);\">farmers</span> <span title=\"0.896\" style=\"background-color: rgba(80, 31, 139, 0.5);\">celebrate</span> <span title=\"0.518\" style=\"background-color: rgba(153, 149, 198, 0.5);\">spring</span> <span title=\"0.258\" style=\"background-color: rgba(215, 215, 233, 0.5);\">by</span> <span title=\"0.587\" style=\"background-color: rgba(136, 133, 190, 0.5);\">spreading</span> <span title=\"0.432\" style=\"background-color: rgba(174, 173, 210, 0.5);\">shit</span> <span title=\"0.507\" style=\"background-color: rgba(156, 152, 199, 0.5);\">everywhere</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.3312, 1.0000, 0.8963, 0.5183, 0.2580, 0.5866, 0.4324, 0.5070])"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'test_text=\"farmers celebrate spring by spreading shit everywhere\"                           \n",
    "txt_ci.show_intrinsic_attention(test_text,cmap=cm.Purples)\n",
    "txt_ci.intrinsic_attention(test_text)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.3687, 0.6313]))"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace;\"><span title=\"0.327\" style=\"background-color: rgba(199, 200, 225, 0.5);\">xxbos</span> <span title=\"0.523\" style=\"background-color: rgba(152, 148, 197, 0.5);\">i</span> <span title=\"1.000\" style=\"background-color: rgba(63, 0, 125, 0.5);\">celebrate</span> <span title=\"0.605\" style=\"background-color: rgba(133, 129, 188, 0.5);\">spring</span> <span title=\"0.264\" style=\"background-color: rgba(214, 215, 233, 0.5);\">by</span> <span title=\"0.679\" style=\"background-color: rgba(118, 106, 176, 0.5);\">spreading</span> <span title=\"0.452\" style=\"background-color: rgba(169, 167, 207, 0.5);\">shit</span> <span title=\"0.610\" style=\"background-color: rgba(131, 128, 187, 0.5);\">everywhere</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.3273, 0.5232, 1.0000, 0.6049, 0.2635, 0.6785, 0.4522, 0.6096])"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text=\"I celebrate spring by spreading shit everywhere\"                           \n",
    "txt_ci.show_intrinsic_attention(test_text,cmap=cm.Purples)\n",
    "txt_ci.intrinsic_attention(test_text)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.9413, 0.0587]))"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace;\"><span title=\"0.261\" style=\"background-color: rgba(215, 215, 233, 0.5);\">xxbos</span> <span title=\"0.767\" style=\"background-color: rgba(102, 74, 160, 0.5);\">trump</span> <span title=\"1.000\" style=\"background-color: rgba(63, 0, 125, 0.5);\">celebrates</span> <span title=\"0.666\" style=\"background-color: rgba(120, 110, 178, 0.5);\">spring</span> <span title=\"0.290\" style=\"background-color: rgba(208, 208, 230, 0.5);\">by</span> <span title=\"0.779\" style=\"background-color: rgba(100, 70, 158, 0.5);\">spreading</span> <span title=\"0.452\" style=\"background-color: rgba(169, 167, 207, 0.5);\">shit</span> <span title=\"0.500\" style=\"background-color: rgba(158, 154, 200, 0.5);\">everywhere</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2608, 0.7669, 1.0000, 0.6660, 0.2898, 0.7790, 0.4518, 0.4999])"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change farmer into other words (im just using trump as an example)\n",
    "test_text= \"trump celebrates spring by spreading shit everywhere\"\n",
    "txt_ci.show_intrinsic_attention(test_text,cmap=cm.Purples)\n",
    "txt_ci.intrinsic_attention(test_text)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.4206, 0.5794]))"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace;\"><span title=\"0.260\" style=\"background-color: rgba(215, 215, 233, 0.5);\">xxbos</span> <span title=\"0.798\" style=\"background-color: rgba(97, 64, 155, 0.5);\">trump</span> <span title=\"1.000\" style=\"background-color: rgba(63, 0, 125, 0.5);\">celebrates</span> <span title=\"0.677\" style=\"background-color: rgba(118, 106, 176, 0.5);\">spring</span> <span title=\"0.237\" style=\"background-color: rgba(220, 220, 236, 0.5);\">by</span> <span title=\"0.662\" style=\"background-color: rgba(121, 111, 179, 0.5);\">putting</span> <span title=\"0.561\" style=\"background-color: rgba(143, 139, 193, 0.5);\">shit</span> <span title=\"0.579\" style=\"background-color: rgba(138, 135, 190, 0.5);\">everywhere</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2596, 0.7983, 1.0000, 0.6767, 0.2368, 0.6616, 0.5615, 0.5792])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text= \"trump celebrates spring by putting shit everywhere\"\n",
    "txt_ci.show_intrinsic_attention(test_text,cmap=cm.Purples)\n",
    "txt_ci.intrinsic_attention(test_text)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.2685, 0.7315]))"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3:\n",
    "Using numbers to start the sentence makes the classifier think it is not a satire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace;\"><span title=\"0.412\" style=\"background-color: rgba(179, 178, 214, 0.5);\">xxbos</span> <span title=\"1.000\" style=\"background-color: rgba(63, 0, 125, 0.5);\">16</span> <span title=\"0.772\" style=\"background-color: rgba(102, 73, 159, 0.5);\">farmers</span> <span title=\"0.761\" style=\"background-color: rgba(104, 77, 161, 0.5);\">celebrate</span> <span title=\"0.492\" style=\"background-color: rgba(159, 155, 200, 0.5);\">spring</span> <span title=\"0.252\" style=\"background-color: rgba(217, 217, 234, 0.5);\">by</span> <span title=\"0.553\" style=\"background-color: rgba(145, 141, 194, 0.5);\">spreading</span> <span title=\"0.437\" style=\"background-color: rgba(173, 172, 210, 0.5);\">shit</span> <span title=\"0.502\" style=\"background-color: rgba(157, 153, 199, 0.5);\">everywhere</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.4120, 1.0000, 0.7723, 0.7613, 0.4925, 0.2522, 0.5531, 0.4371, 0.5020])"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text=\"16 farmers celebrate spring by spreading shit everywhere\"                           \n",
    "txt_ci.show_intrinsic_attention(test_text,cmap=cm.Purples)\n",
    "txt_ci.intrinsic_attention(test_text)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.9216, 0.0784]))"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace;\"><span title=\"0.446\" style=\"background-color: rgba(170, 168, 208, 0.5);\">xxbos</span> <span title=\"1.000\" style=\"background-color: rgba(63, 0, 125, 0.5);\">16</span> <span title=\"0.694\" style=\"background-color: rgba(115, 100, 173, 0.5);\">things</span> <span title=\"0.385\" style=\"background-color: rgba(185, 186, 218, 0.5);\">you</span> <span title=\"0.325\" style=\"background-color: rgba(199, 200, 225, 0.5);\">need</span> <span title=\"0.120\" style=\"background-color: rgba(239, 237, 245, 0.5);\">to</span> <span title=\"0.260\" style=\"background-color: rgba(215, 215, 233, 0.5);\">know</span> <span title=\"0.242\" style=\"background-color: rgba(219, 219, 235, 0.5);\">about</span> <span title=\"0.808\" style=\"background-color: rgba(95, 61, 153, 0.5);\">sleep</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.4460, 1.0000, 0.6942, 0.3850, 0.3246, 0.1200, 0.2600, 0.2423, 0.8082])"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text=\"16 things you need to know about sleep\"\n",
    "txt_ci.show_intrinsic_attention(test_text,cmap=cm.Purples)\n",
    "txt_ci.intrinsic_attention(test_text)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.9980, 0.0020]))"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other experiments:\n",
    "Change position of hideous to see if classifier still gives it high weight, meaning hideous has the trait of being recognized as a sarcastic word independent of its position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace;\"><span title=\"0.190\" style=\"background-color: rgba(228, 227, 239, 0.5);\">xxbos</span> <span title=\"0.388\" style=\"background-color: rgba(184, 185, 217, 0.5);\">even</span> <span title=\"0.195\" style=\"background-color: rgba(227, 226, 239, 0.5);\">xxunk</span> <span title=\"0.638\" style=\"background-color: rgba(125, 119, 183, 0.5);\">embarrassed</span> <span title=\"0.143\" style=\"background-color: rgba(236, 234, 243, 0.5);\">by</span> <span title=\"1.000\" style=\"background-color: rgba(63, 0, 125, 0.5);\">hideous</span> <span title=\"0.398\" style=\"background-color: rgba(182, 182, 216, 0.5);\">gender</span> <span title=\"0.318\" style=\"background-color: rgba(201, 202, 226, 0.5);\">reveal</span> <span title=\"0.266\" style=\"background-color: rgba(214, 214, 233, 0.5);\">party</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1903, 0.3877, 0.1952, 0.6380, 0.1432, 1.0000, 0.3985, 0.3177, 0.2659])"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text=\"even foetus embarrassed by hideous gender reveal party\"\n",
    "txt_ci.show_intrinsic_attention(test_text,cmap=cm.Purples)\n",
    "txt_ci.intrinsic_attention(test_text)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.2719, 0.7281]))"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace;\"><span title=\"0.248\" style=\"background-color: rgba(218, 218, 235, 0.5);\">xxbos</span> <span title=\"0.596\" style=\"background-color: rgba(134, 131, 189, 0.5);\">even</span> <span title=\"1.000\" style=\"background-color: rgba(63, 0, 125, 0.5);\">hideous</span> <span title=\"0.185\" style=\"background-color: rgba(229, 227, 240, 0.5);\">xxunk</span> <span title=\"0.734\" style=\"background-color: rgba(108, 86, 166, 0.5);\">embarrassed</span> <span title=\"0.165\" style=\"background-color: rgba(232, 230, 241, 0.5);\">by</span> <span title=\"0.567\" style=\"background-color: rgba(141, 138, 192, 0.5);\">gender</span> <span title=\"0.352\" style=\"background-color: rgba(193, 194, 222, 0.5);\">reveal</span> <span title=\"0.375\" style=\"background-color: rgba(188, 189, 220, 0.5);\">party</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2481, 0.5960, 1.0000, 0.1853, 0.7339, 0.1651, 0.5666, 0.3521, 0.3745])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text=\"even hideous foetus embarrassed by gender reveal party\"\n",
    "txt_ci.show_intrinsic_attention(test_text,cmap=cm.Purples)\n",
    "txt_ci.intrinsic_attention(test_text)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.2497, 0.7503]))"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Text</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos the arts : what were they ?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.43</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos the onion apologizes</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos breaking : we 're doing a bad job</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.22</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxunk and the xxunk : breaking down racial barriers between black , white xxunk</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos this great song , bar sources report</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos inside : the fetish photography of german chancellor xxunk xxunk</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos now you can see into your future . and it 's pretty xxunk scary .</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos the elderly : do they suspect ?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.38</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos inside : america rates the skin colors</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.23</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos whatsapp finally adds fully - encrypted video calling service</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "txt_ci.show_top_losses(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation notes\n",
    "\n",
    "Classification Patterns that I detected: \n",
    "* In general, I found that the classifier gives greater attention to the first couple of words that start the sentence and the last couple of words that ends a sentence. If the first couple of words are the strong words (i.e. words that classifier thinks is likely to be sarcastic, examples include celebrate, hideous, farmers, etc.) then the classifier is more likely to think it is a satire; \n",
    "* Changing a stronger word into a weaker word (e.g. change farmers into trump) will make the classifier shift attention to other strongly charged words. For example, if I change the word \"farmer\" in headline \"farmers celebrates spring by spreading shit everywhere\" into \"trump\", the classifier pays more attention to \"spreading\" than before (and because it probably thinks spreading is sarcastic, it is more confident that the trump headline is a satire than the farmers headline). \n",
    "\n",
    "# When does the classifier misclassify headlines:\n",
    "\n",
    "1) I feel like there are certain strong words that the classifier tends to determine as a satire (e.g. celebrate, hideous, farmers) and certain words that the classifier thinks is not satire (e.g. I, we). For example, for one of the examiples I tested above, when I use \"farmers\" as the subject the classifier thinks the headline \"farmers celebrate spring by spreading shit everywhere\" is a satire; when I change the subject from  \"farmers\" to \"I\", it changes the judgement of the classifier (it thinks this is not a satire with 94%+ confidence). I have tried several different examples—so I think if a satires starts with \"I\" or \"we\", the classifier is likely to misclassify it as non-satire. If a sober headline has strong words such as \"hideous\", it is slightly more likely to misclassify it as satire.\n",
    "\n",
    "3) I found that if a headline starts with numbers (e.g. \"16 things you need to know\"), it is rarely classified as a satire. When I put 'farmers celebrates...' the classifier is almost 50% confident that it is a satire. However, if I add a number such as 16 in front of the sentence (\"16 farmers celebrates...\"), the classifier is 90%+ confident that it is not a satire—so I think if a satire starts with a number, the classifier is likely to misclassify it as non-satire.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Save your classifier\n",
    "Now that we've trained the classifier, you're ready for Part 2. You'll use this saved file in your bot later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify.export(file='satire_awd.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, you'll use it like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "serve_classifier = load_learner(path=data_path, file='satire_awd.pkl')\n",
    "serve_lm = load_learner(path=data_path, file='headlines-lm.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.9801, 0.0199]))"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serve_classifier.predict('How the New Syria Took Shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rising Seas will win a national representation heat .'"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serve_lm.predict('Rising Seas', n_words=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: add the bot code. \n",
    "\n",
    "See the assignment document for what the bot code should look like. You can add it just below here, but you are also welcome to create a new notebook where you put that code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# its in the other notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
